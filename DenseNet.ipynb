{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "import keras\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define train data\n",
    "columns = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'class', 'fname']\n",
    "train_images_dir = os.path.join('./', 'cars_train')\n",
    "train_labels_mat = scipy.io.loadmat('cars_train_annos.mat')\n",
    "train_labels_data = [[row.flat[0] for row in line] for line in train_labels_mat['annotations'][0]]\n",
    "df_train = pd.DataFrame(train_labels_data, columns=columns)\n",
    "print(\"\\n================================\\nTrain Data\\n================================\\n\", df_train)\n",
    "\n",
    "# Define test data\n",
    "columns = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'fname']\n",
    "test_images_dir = os.path.join('./', 'cars_test')\n",
    "test_labels_mat = scipy.io.loadmat('cars_test_annos.mat')\n",
    "test_labels_data = [[row.flat[0] for row in line] for line in test_labels_mat['annotations'][0]]\n",
    "df_test = pd.DataFrame(test_labels_data, columns=columns) \n",
    "print(\"\\n================================\\nTest Data\\n================================\\n\", df_test)\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "nb_train_samples = 6114\n",
    "nb_validation_samples = 2000\n",
    "batch_size = 15\n",
    "epochs = 100\n",
    "\n",
    "model = applications.DenseNet(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3), classes=196)\n",
    "\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(196, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_image_generator = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            rotation_range=45,\n",
    "                            width_shift_range=.15,\n",
    "                            height_shift_range=.15,\n",
    "                            horizontal_flip=True,\n",
    "                            zoom_range=0.5\n",
    "                        )\n",
    "\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_images_dir,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           shuffle=True,\n",
    "                                                           class_mode='categorical')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                             directory=test_images_dir,\n",
    "                                                             target_size=(img_height, img_width),\n",
    "                                                             class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"densenet_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "logger = keras.callbacks.TensorBoard(log_dir=\"logs\", write_graph=True, histogram_freq=5)\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_data_gen,\n",
    "steps_per_epoch=6114 // batch_size,\n",
    "epochs = epochs,\n",
    "validation_data = test_data_gen,\n",
    "validation_steps=2000 // batch_size,\n",
    "callbacks = [checkpoint, early, logger])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
