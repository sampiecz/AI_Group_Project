{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/samuel/.virtualenvs/ai/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "import keras\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define train data\n",
    "columns = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'class', 'fname']\n",
    "train_images_dir = os.path.join('./', 'cars_train')\n",
    "train_labels_mat = scipy.io.loadmat('cars_train_annos.mat')\n",
    "train_labels_data = [[row.flat[0] for row in line] for line in train_labels_mat['annotations'][0]]\n",
    "df_train = pd.DataFrame(train_labels_data, columns=columns)\n",
    "\n",
    "# Define test data\n",
    "columns = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'fname']\n",
    "test_images_dir = os.path.join('./', 'cars_test')\n",
    "test_labels_mat = scipy.io.loadmat('cars_test_annos.mat')\n",
    "test_labels_data = [[row.flat[0] for row in line] for line in test_labels_mat['annotations'][0]]\n",
    "df_test = pd.DataFrame(test_labels_data, columns=columns) \n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "nb_train_samples = 6114\n",
    "nb_validation_samples = 2000\n",
    "batch_size = 15\n",
    "epochs = 100\n",
    "\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(196, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg19_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "logger = keras.callbacks.TensorBoard(log_dir=\"logs\", write_graph=True, histogram_freq=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6144 images belonging to 196 classes.\n",
      "Found 2000 images belonging to 196 classes.\n",
      "Epoch 1/100\n",
      "407/407 [==============================] - 58s 143ms/step - loss: 5.2757 - accuracy: 0.0067 - val_loss: 5.2862 - val_accuracy: 0.0090\n",
      "Epoch 2/100\n",
      "407/407 [==============================] - 58s 143ms/step - loss: 5.2757 - accuracy: 0.0084 - val_loss: 5.2832 - val_accuracy: 0.0081\n",
      "Epoch 3/100\n",
      "407/407 [==============================] - 58s 143ms/step - loss: 5.2755 - accuracy: 0.0064 - val_loss: 5.2840 - val_accuracy: 0.0086\n",
      "Epoch 4/100\n",
      "407/407 [==============================] - 59s 144ms/step - loss: 5.2722 - accuracy: 0.0052 - val_loss: 5.2693 - val_accuracy: 0.0081\n",
      "Epoch 5/100\n",
      "407/407 [==============================] - 59s 144ms/step - loss: 5.2711 - accuracy: 0.0077 - val_loss: 5.2669 - val_accuracy: 0.0091\n",
      "Epoch 6/100\n",
      "407/407 [==============================] - 59s 145ms/step - loss: 5.2667 - accuracy: 0.0089 - val_loss: 5.2806 - val_accuracy: 0.0091\n",
      "Epoch 7/100\n",
      "407/407 [==============================] - 57s 141ms/step - loss: 5.2618 - accuracy: 0.0103 - val_loss: 5.2944 - val_accuracy: 0.0081\n",
      "Epoch 8/100\n",
      "407/407 [==============================] - 59s 144ms/step - loss: 5.2599 - accuracy: 0.0092 - val_loss: 5.3018 - val_accuracy: 0.0111\n",
      "Epoch 9/100\n",
      "407/407 [==============================] - 59s 144ms/step - loss: 5.2537 - accuracy: 0.0095 - val_loss: 5.2946 - val_accuracy: 0.0071\n",
      "Epoch 10/100\n",
      "407/407 [==============================] - 58s 143ms/step - loss: 5.2370 - accuracy: 0.0110 - val_loss: 5.2616 - val_accuracy: 0.0106\n",
      "Epoch 11/100\n",
      "407/407 [==============================] - 60s 147ms/step - loss: 5.2182 - accuracy: 0.0166 - val_loss: 5.1699 - val_accuracy: 0.0121\n",
      "Epoch 12/100\n",
      "407/407 [==============================] - 57s 141ms/step - loss: 5.1838 - accuracy: 0.0167 - val_loss: 5.2673 - val_accuracy: 0.0136\n",
      "Epoch 13/100\n",
      "407/407 [==============================] - 58s 143ms/step - loss: 5.1256 - accuracy: 0.0266 - val_loss: 5.3119 - val_accuracy: 0.0151\n",
      "Epoch 14/100\n",
      "407/407 [==============================] - 60s 148ms/step - loss: 5.0452 - accuracy: 0.0289 - val_loss: 5.1774 - val_accuracy: 0.0257\n",
      "Epoch 15/100\n",
      "407/407 [==============================] - 62s 154ms/step - loss: 4.8805 - accuracy: 0.0448 - val_loss: 5.0077 - val_accuracy: 0.0307\n",
      "Epoch 16/100\n",
      "407/407 [==============================] - 59s 144ms/step - loss: 4.6940 - accuracy: 0.0572 - val_loss: 4.9446 - val_accuracy: 0.0438\n",
      "Epoch 17/100\n",
      "407/407 [==============================] - 60s 149ms/step - loss: 4.4367 - accuracy: 0.0862 - val_loss: 4.9458 - val_accuracy: 0.0650\n",
      "Epoch 18/100\n",
      "407/407 [==============================] - 61s 149ms/step - loss: 4.1435 - accuracy: 0.1159 - val_loss: 4.3253 - val_accuracy: 0.0801\n",
      "Epoch 19/100\n",
      "407/407 [==============================] - 62s 153ms/step - loss: 3.7843 - accuracy: 0.1599 - val_loss: 3.4055 - val_accuracy: 0.1270\n",
      "Epoch 20/100\n",
      "407/407 [==============================] - 62s 152ms/step - loss: 3.3745 - accuracy: 0.2342 - val_loss: 4.5106 - val_accuracy: 0.1219\n",
      "Epoch 21/100\n",
      "407/407 [==============================] - 60s 146ms/step - loss: 2.9798 - accuracy: 0.3002 - val_loss: 3.4725 - val_accuracy: 0.1662\n",
      "Epoch 22/100\n",
      "407/407 [==============================] - 59s 145ms/step - loss: 2.5244 - accuracy: 0.3832 - val_loss: 2.9053 - val_accuracy: 0.1940\n",
      "Epoch 23/100\n",
      "407/407 [==============================] - 60s 147ms/step - loss: 2.1158 - accuracy: 0.4706 - val_loss: 4.3020 - val_accuracy: 0.1824\n",
      "Epoch 24/100\n",
      "407/407 [==============================] - 60s 146ms/step - loss: 1.7199 - accuracy: 0.5506 - val_loss: 3.7970 - val_accuracy: 0.2010\n",
      "Epoch 25/100\n",
      "407/407 [==============================] - 58s 143ms/step - loss: 1.3690 - accuracy: 0.6293 - val_loss: 3.5841 - val_accuracy: 0.2408\n",
      "Epoch 26/100\n",
      "407/407 [==============================] - 61s 150ms/step - loss: 1.0990 - accuracy: 0.7024 - val_loss: 5.1317 - val_accuracy: 0.2327\n",
      "Epoch 27/100\n",
      "407/407 [==============================] - 60s 147ms/step - loss: 0.8701 - accuracy: 0.7613 - val_loss: 4.2725 - val_accuracy: 0.2393\n",
      "Epoch 28/100\n",
      "407/407 [==============================] - 57s 141ms/step - loss: 0.6894 - accuracy: 0.8049 - val_loss: 3.8776 - val_accuracy: 0.2398\n",
      "Epoch 29/100\n",
      "407/407 [==============================] - 62s 153ms/step - loss: 0.5502 - accuracy: 0.8431 - val_loss: 2.8422 - val_accuracy: 0.2534\n",
      "Epoch 30/100\n",
      "407/407 [==============================] - 62s 153ms/step - loss: 0.4720 - accuracy: 0.8578 - val_loss: 3.9824 - val_accuracy: 0.2554\n",
      "Epoch 31/100\n",
      "407/407 [==============================] - 62s 153ms/step - loss: 0.3609 - accuracy: 0.8920 - val_loss: 5.5781 - val_accuracy: 0.2700\n",
      "Epoch 32/100\n",
      "407/407 [==============================] - 62s 153ms/step - loss: 0.3392 - accuracy: 0.9028 - val_loss: 3.1610 - val_accuracy: 0.2564\n",
      "Epoch 33/100\n",
      "407/407 [==============================] - 62s 153ms/step - loss: 0.2966 - accuracy: 0.9128 - val_loss: 3.2354 - val_accuracy: 0.2615\n",
      "Epoch 34/100\n",
      "407/407 [==============================] - 60s 148ms/step - loss: 0.2496 - accuracy: 0.9237 - val_loss: 3.8302 - val_accuracy: 0.2615\n",
      "Epoch 35/100\n",
      "407/407 [==============================] - 60s 148ms/step - loss: 0.2372 - accuracy: 0.9313 - val_loss: 4.7029 - val_accuracy: 0.2786\n",
      "Epoch 36/100\n",
      "407/407 [==============================] - 57s 141ms/step - loss: 0.1831 - accuracy: 0.9490 - val_loss: 3.9798 - val_accuracy: 0.2821\n",
      "Epoch 37/100\n",
      "407/407 [==============================] - 57s 140ms/step - loss: 0.1780 - accuracy: 0.9476 - val_loss: 4.2413 - val_accuracy: 0.2897\n",
      "Epoch 38/100\n",
      "407/407 [==============================] - 57s 140ms/step - loss: 0.1398 - accuracy: 0.9601 - val_loss: 6.2021 - val_accuracy: 0.2922\n",
      "Epoch 39/100\n",
      "407/407 [==============================] - 57s 141ms/step - loss: 0.1375 - accuracy: 0.9639 - val_loss: 5.8030 - val_accuracy: 0.2725\n",
      "Epoch 40/100\n",
      "407/407 [==============================] - 57s 140ms/step - loss: 0.1351 - accuracy: 0.9586 - val_loss: 4.9495 - val_accuracy: 0.2700\n",
      "Epoch 41/100\n",
      "407/407 [==============================] - 57s 141ms/step - loss: 0.1223 - accuracy: 0.9649 - val_loss: 5.6535 - val_accuracy: 0.2997\n",
      "Epoch 42/100\n",
      "407/407 [==============================] - 57s 141ms/step - loss: 0.1098 - accuracy: 0.9677 - val_loss: 6.6348 - val_accuracy: 0.2841\n",
      "Epoch 43/100\n",
      "407/407 [==============================] - 57s 140ms/step - loss: 0.0920 - accuracy: 0.9731 - val_loss: 4.0252 - val_accuracy: 0.3008\n",
      "Epoch 44/100\n",
      "407/407 [==============================] - 57s 141ms/step - loss: 0.1093 - accuracy: 0.9664 - val_loss: 4.6318 - val_accuracy: 0.2846\n",
      "Epoch 45/100\n",
      "407/407 [==============================] - 57s 140ms/step - loss: 0.0861 - accuracy: 0.9729 - val_loss: 5.3227 - val_accuracy: 0.3073\n",
      "Epoch 46/100\n",
      "407/407 [==============================] - 59s 145ms/step - loss: 0.0909 - accuracy: 0.9744 - val_loss: 4.8390 - val_accuracy: 0.2730\n",
      "Epoch 47/100\n",
      "407/407 [==============================] - 59s 145ms/step - loss: 0.0861 - accuracy: 0.9761 - val_loss: 4.9370 - val_accuracy: 0.3083\n",
      "Epoch 48/100\n",
      "407/407 [==============================] - 59s 145ms/step - loss: 0.0865 - accuracy: 0.9765 - val_loss: 5.4328 - val_accuracy: 0.2892\n",
      "Epoch 49/100\n",
      "407/407 [==============================] - 58s 142ms/step - loss: 0.0645 - accuracy: 0.9808 - val_loss: 4.1825 - val_accuracy: 0.2917\n",
      "Epoch 50/100\n",
      "407/407 [==============================] - 61s 151ms/step - loss: 0.0706 - accuracy: 0.9794 - val_loss: 5.4826 - val_accuracy: 0.3093\n",
      "Epoch 51/100\n",
      "407/407 [==============================] - 60s 148ms/step - loss: 0.0697 - accuracy: 0.9793 - val_loss: 3.9992 - val_accuracy: 0.2887\n",
      "Epoch 52/100\n",
      "407/407 [==============================] - 59s 145ms/step - loss: 0.0677 - accuracy: 0.9808 - val_loss: 5.3366 - val_accuracy: 0.3038\n",
      "Epoch 53/100\n",
      "407/407 [==============================] - 58s 142ms/step - loss: 0.0595 - accuracy: 0.9839 - val_loss: 5.7925 - val_accuracy: 0.3063\n",
      "Epoch 54/100\n",
      "407/407 [==============================] - 59s 146ms/step - loss: 0.0492 - accuracy: 0.9869 - val_loss: 4.4098 - val_accuracy: 0.3234\n",
      "Epoch 55/100\n",
      "407/407 [==============================] - 62s 151ms/step - loss: 0.0592 - accuracy: 0.9834 - val_loss: 5.8648 - val_accuracy: 0.2877\n",
      "Epoch 56/100\n",
      "407/407 [==============================] - 60s 148ms/step - loss: 0.0492 - accuracy: 0.9875 - val_loss: 4.4700 - val_accuracy: 0.3128\n",
      "Epoch 57/100\n",
      "407/407 [==============================] - 62s 151ms/step - loss: 0.0516 - accuracy: 0.9851 - val_loss: 4.2935 - val_accuracy: 0.2947\n",
      "Epoch 58/100\n",
      "407/407 [==============================] - 58s 143ms/step - loss: 0.0481 - accuracy: 0.9865 - val_loss: 4.6264 - val_accuracy: 0.3008\n",
      "Epoch 59/100\n",
      "407/407 [==============================] - 60s 148ms/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 4.1682 - val_accuracy: 0.2982\n",
      "Epoch 60/100\n",
      "407/407 [==============================] - 61s 151ms/step - loss: 0.0442 - accuracy: 0.9882 - val_loss: 4.8052 - val_accuracy: 0.3144\n",
      "Epoch 61/100\n",
      "407/407 [==============================] - 62s 153ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 3.2180 - val_accuracy: 0.2932\n",
      "Epoch 62/100\n",
      "407/407 [==============================] - 61s 151ms/step - loss: 0.0408 - accuracy: 0.9882 - val_loss: 5.6025 - val_accuracy: 0.3043\n",
      "Epoch 63/100\n",
      "407/407 [==============================] - 60s 148ms/step - loss: 0.0423 - accuracy: 0.9902 - val_loss: 6.2635 - val_accuracy: 0.3128\n",
      "Epoch 64/100\n",
      "407/407 [==============================] - 62s 151ms/step - loss: 0.0425 - accuracy: 0.9879 - val_loss: 5.0418 - val_accuracy: 0.3023\n",
      "Epoch 65/100\n",
      "221/407 [===============>..............] - ETA: 25s - loss: 0.0285 - accuracy: 0.9912"
     ]
    }
   ],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_image_generator = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                        )\n",
    "\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_images_dir,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           shuffle=True,\n",
    "                                                           class_mode='categorical')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                             directory=test_images_dir,\n",
    "                                                             target_size=(img_height, img_width),\n",
    "                                                             class_mode='categorical')\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_data_gen,\n",
    "steps_per_epoch=6114 // batch_size,\n",
    "epochs = epochs,\n",
    "validation_data = test_data_gen,\n",
    "validation_steps=2000 // batch_size,\n",
    "callbacks = [checkpoint, early, logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out image augmentation, l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/.virtualenvs/ai/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6144 images belonging to 196 classes.\n",
      "Found 2000 images belonging to 196 classes.\n",
      "Epoch 1/100\n",
      "407/407 [==============================] - 75s 184ms/step - loss: 1058.9792 - accuracy: 0.0049 - val_loss: 975.2362 - val_accuracy: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/.virtualenvs/ai/lib/python3.6/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/home/samuel/.virtualenvs/ai/lib/python3.6/site-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "407/407 [==============================] - 71s 173ms/step - loss: 900.4309 - accuracy: 0.0066 - val_loss: 829.2509 - val_accuracy: 0.0091\n",
      "Epoch 3/100\n",
      "407/407 [==============================] - 70s 173ms/step - loss: 765.7074 - accuracy: 0.0072 - val_loss: 705.2344 - val_accuracy: 0.0111\n",
      "Epoch 4/100\n",
      "407/407 [==============================] - 70s 172ms/step - loss: 651.2600 - accuracy: 0.0072 - val_loss: 599.8989 - val_accuracy: 0.0086\n",
      "Epoch 5/100\n",
      "407/407 [==============================] - 73s 179ms/step - loss: 554.0374 - accuracy: 0.0062 - val_loss: 510.4167 - val_accuracy: 0.0086\n",
      "Epoch 6/100\n",
      "407/407 [==============================] - 71s 174ms/step - loss: 471.4469 - accuracy: 0.0059 - val_loss: 434.3623 - val_accuracy: 0.0091\n",
      "Epoch 7/100\n",
      "407/407 [==============================] - 72s 176ms/step - loss: 401.2867 - accuracy: 0.0080 - val_loss: 369.8246 - val_accuracy: 0.0081\n",
      "Epoch 8/100\n",
      "407/407 [==============================] - 73s 179ms/step - loss: 341.6854 - accuracy: 0.0089 - val_loss: 314.9307 - val_accuracy: 0.0096\n",
      "Epoch 9/100\n",
      "407/407 [==============================] - 72s 177ms/step - loss: 291.0546 - accuracy: 0.0079 - val_loss: 268.3559 - val_accuracy: 0.0096\n",
      "Epoch 10/100\n",
      "407/407 [==============================] - 72s 177ms/step - loss: 248.0428 - accuracy: 0.0095 - val_loss: 228.7217 - val_accuracy: 0.0076\n",
      "Epoch 11/100\n",
      "407/407 [==============================] - 70s 173ms/step - loss: 211.5051 - accuracy: 0.0102 - val_loss: 195.1111 - val_accuracy: 0.0106\n",
      "Epoch 12/100\n",
      "407/407 [==============================] - 73s 178ms/step - loss: 180.4664 - accuracy: 0.0082 - val_loss: 166.5263 - val_accuracy: 0.0096\n",
      "Epoch 13/100\n",
      "407/407 [==============================] - 73s 179ms/step - loss: 154.0972 - accuracy: 0.0123 - val_loss: 142.3407 - val_accuracy: 0.0096\n",
      "Epoch 14/100\n",
      "407/407 [==============================] - 74s 183ms/step - loss: 131.6970 - accuracy: 0.0107 - val_loss: 121.6391 - val_accuracy: 0.0096\n",
      "Epoch 15/100\n",
      "407/407 [==============================] - 74s 182ms/step - loss: 112.6661 - accuracy: 0.0111 - val_loss: 104.1254 - val_accuracy: 0.0101\n",
      "Epoch 16/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 96.4944 - accuracy: 0.0138 - val_loss: 89.2260 - val_accuracy: 0.0091\n",
      "Epoch 17/100\n",
      "407/407 [==============================] - 73s 180ms/step - loss: 82.7411 - accuracy: 0.0148 - val_loss: 76.7158 - val_accuracy: 0.0156\n",
      "Epoch 18/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 71.0306 - accuracy: 0.0128 - val_loss: 65.6423 - val_accuracy: 0.0101\n",
      "Epoch 19/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 61.0946 - accuracy: 0.0152 - val_loss: 56.6155 - val_accuracy: 0.0171\n",
      "Epoch 20/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 52.6566 - accuracy: 0.0144 - val_loss: 48.9165 - val_accuracy: 0.0277\n",
      "Epoch 21/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 45.4384 - accuracy: 0.0216 - val_loss: 42.3018 - val_accuracy: 0.0227\n",
      "Epoch 22/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 39.3104 - accuracy: 0.0271 - val_loss: 36.2546 - val_accuracy: 0.0307\n",
      "Epoch 23/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 34.0529 - accuracy: 0.0349 - val_loss: 31.5092 - val_accuracy: 0.0403\n",
      "Epoch 24/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 29.5667 - accuracy: 0.0449 - val_loss: 27.2127 - val_accuracy: 0.0388\n",
      "Epoch 25/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 25.7462 - accuracy: 0.0521 - val_loss: 23.9638 - val_accuracy: 0.0599\n",
      "Epoch 26/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 22.4938 - accuracy: 0.0666 - val_loss: 20.7703 - val_accuracy: 0.0786\n",
      "Epoch 27/100\n",
      "407/407 [==============================] - 75s 184ms/step - loss: 19.6779 - accuracy: 0.0890 - val_loss: 19.0264 - val_accuracy: 0.0922\n",
      "Epoch 28/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 17.2509 - accuracy: 0.1100 - val_loss: 16.1925 - val_accuracy: 0.1219\n",
      "Epoch 29/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 15.2183 - accuracy: 0.1367 - val_loss: 14.1094 - val_accuracy: 0.1607\n",
      "Epoch 30/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 13.4382 - accuracy: 0.1686 - val_loss: 13.5560 - val_accuracy: 0.1854\n",
      "Epoch 31/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 11.9159 - accuracy: 0.2015 - val_loss: 10.2783 - val_accuracy: 0.2358\n",
      "Epoch 32/100\n",
      "407/407 [==============================] - 76s 187ms/step - loss: 10.6000 - accuracy: 0.2411 - val_loss: 10.5774 - val_accuracy: 0.2458\n",
      "Epoch 33/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 9.5130 - accuracy: 0.2695 - val_loss: 9.6014 - val_accuracy: 0.3038\n",
      "Epoch 34/100\n",
      "407/407 [==============================] - 76s 187ms/step - loss: 8.5879 - accuracy: 0.2930 - val_loss: 8.5681 - val_accuracy: 0.3219\n",
      "Epoch 35/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 7.7978 - accuracy: 0.3223 - val_loss: 6.5549 - val_accuracy: 0.3526\n",
      "Epoch 36/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 7.1018 - accuracy: 0.3546 - val_loss: 7.4277 - val_accuracy: 0.3632\n",
      "Epoch 37/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 6.5085 - accuracy: 0.3885 - val_loss: 5.8354 - val_accuracy: 0.3804\n",
      "Epoch 38/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 6.0412 - accuracy: 0.4097 - val_loss: 5.1988 - val_accuracy: 0.4015\n",
      "Epoch 39/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 5.6438 - accuracy: 0.4301 - val_loss: 6.4950 - val_accuracy: 0.3935\n",
      "Epoch 40/100\n",
      "407/407 [==============================] - 76s 186ms/step - loss: 5.2785 - accuracy: 0.4614 - val_loss: 5.1758 - val_accuracy: 0.4725\n",
      "Epoch 41/100\n",
      "407/407 [==============================] - 76s 187ms/step - loss: 4.9221 - accuracy: 0.4914 - val_loss: 5.6811 - val_accuracy: 0.4519\n",
      "Epoch 42/100\n",
      "407/407 [==============================] - 75s 184ms/step - loss: 4.6832 - accuracy: 0.5096 - val_loss: 4.9412 - val_accuracy: 0.4670\n",
      "Epoch 43/100\n",
      "407/407 [==============================] - 75s 185ms/step - loss: 4.4865 - accuracy: 0.5286 - val_loss: 5.2498 - val_accuracy: 0.3950\n",
      "Epoch 44/100\n",
      "407/407 [==============================] - 75s 184ms/step - loss: 4.3032 - accuracy: 0.5417 - val_loss: 4.8540 - val_accuracy: 0.4841\n",
      "Epoch 45/100\n",
      "213/407 [==============>...............] - ETA: 32s - loss: 4.2069 - accuracy: 0.5538"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"vgg19_2.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "logger = keras.callbacks.TensorBoard(log_dir=\"vgg19_2\", write_graph=True, histogram_freq=5)\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, kernel_regularizer=regularizers.l2(0.1), activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, kernel_regularizer=regularizers.l2(0.1), activation=\"relu\")(x)\n",
    "predictions = Dense(196, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_image_generator = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            rotation_range=45,\n",
    "                            width_shift_range=.15,\n",
    "                            height_shift_range=.15,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.3\n",
    "                        )\n",
    "\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_images_dir,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           shuffle=True,\n",
    "                                                           class_mode='categorical')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                             directory=test_images_dir,\n",
    "                                                             target_size=(img_height, img_width),\n",
    "                                                             class_mode='categorical')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_data_gen,\n",
    "steps_per_epoch=6114 // batch_size,\n",
    "epochs = epochs,\n",
    "validation_data = test_data_gen,\n",
    "validation_steps=2000 // batch_size,\n",
    "callbacks = [checkpoint, early, logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
